{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a82eb6b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in c:\\users\\my pc\\anaconda3\\lib\\site-packages (3.10.1)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\my pc\\anaconda3\\lib\\site-packages (from SpeechRecognition) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\my pc\\anaconda3\\lib\\site-packages (from SpeechRecognition) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\my pc\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\my pc\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\my pc\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\my pc\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2023.7.22)\n",
      "Collecting pyaudio\n",
      "  Obtaining dependency information for pyaudio from https://files.pythonhosted.org/packages/82/d8/f043c854aad450a76e476b0cf9cda1956419e1dacf1062eb9df3c0055abe/PyAudio-0.2.14-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading PyAudio-0.2.14-cp311-cp311-win_amd64.whl.metadata (2.7 kB)\n",
      "Downloading PyAudio-0.2.14-cp311-cp311-win_amd64.whl (164 kB)\n",
      "   ---------------------------------------- 0.0/164.1 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 10.2/164.1 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 10.2/164.1 kB ? eta -:--:--\n",
      "   --------- ----------------------------- 41.0/164.1 kB 393.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 164.1/164.1 kB 1.2 MB/s eta 0:00:00\n",
      "Installing collected packages: pyaudio\n",
      "Successfully installed pyaudio-0.2.14\n"
     ]
    }
   ],
   "source": [
    "!pip install SpeechRecognition\n",
    "!pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbc826d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblobNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Obtaining dependency information for textblob from https://files.pythonhosted.org/packages/02/07/5fd2945356dd839974d3a25de8a142dc37293c21315729a41e775b5f3569/textblob-0.18.0.post0-py3-none-any.whl.metadata\n",
      "  Downloading textblob-0.18.0.post0-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: nltk>=3.8 in c:\\users\\my pc\\anaconda3\\lib\\site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\my pc\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\my pc\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\my pc\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\my pc\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\my pc\\anaconda3\\lib\\site-packages (from click->nltk>=3.8->textblob) (0.4.6)\n",
      "Downloading textblob-0.18.0.post0-py3-none-any.whl (626 kB)\n",
      "   ---------------------------------------- 0.0/626.3 kB ? eta -:--:--\n",
      "   ---------------------------- ----------- 440.3/626.3 kB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  624.6/626.3 kB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 626.3/626.3 kB 4.4 MB/s eta 0:00:00\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.18.0.post0\n"
     ]
    }
   ],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40af635b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\my pc\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Result: [{'emotion': {'angry': 0.03338118748403713, 'disgust': 1.6623164947270755e-08, 'fear': 0.09717263162047456, 'happy': 0.001976269895309837, 'sad': 0.11854407618457533, 'surprise': 0.0014945933780378905, 'neutral': 99.74743126317449}, 'dominant_emotion': 'neutral', 'region': {'x': 297, 'y': 78, 'w': 179, 'h': 179}, 'face_confidence': 9.194292111962568}]\n",
      "Listening...\n",
      "Speech detected: am I visible in audible to you\n",
      "Result: [{'emotion': {'angry': 0.44353859799640205, 'disgust': 1.2057751136783457e-07, 'fear': 0.04056102578359535, 'happy': 0.020226033438060172, 'sad': 0.2689013169898013, 'surprise': 0.007534104054220655, 'neutral': 99.21923289069737}, 'dominant_emotion': 'neutral', 'region': {'x': 287, 'y': 83, 'w': 263, 'h': 263}, 'face_confidence': 9.209602049493697}]\n",
      "Listening...\n",
      "Speech detected: I want to tell you something right now\n",
      "Result: [{'emotion': {'angry': 0.0951844445116735, 'disgust': 3.6163661500894687e-09, 'fear': 0.03195902591966528, 'happy': 0.05178904940467484, 'sad': 0.09284304745131165, 'surprise': 0.005112423723316531, 'neutral': 99.72310665570419}, 'dominant_emotion': 'neutral', 'region': {'x': 265, 'y': 45, 'w': 277, 'h': 277}, 'face_confidence': 7.590602087031584}]\n",
      "Listening...\n",
      "Speech detected: it was a place in day to day\n",
      "Result: [{'emotion': {'angry': 2.331963926553726, 'disgust': 1.5620688031958707e-05, 'fear': 1.1831886135041714, 'happy': 0.06603306392207742, 'sad': 2.6254242286086082, 'surprise': 0.00995694863377139, 'neutral': 93.78342032432556}, 'dominant_emotion': 'neutral', 'region': {'x': 281, 'y': 43, 'w': 273, 'h': 273}, 'face_confidence': 8.649971153237857}]\n",
      "Listening...\n",
      "Speech detected: you know what when your ideal you do not feel that way that you should actually feel like but when you are doing something you are into something you feel so joyful so amazing it's it's just something which is really great to a discuss I hope you understand right so\n",
      "Result: [{'emotion': {'angry': 0.3729954594746232, 'disgust': 1.2050059838841776e-07, 'fear': 0.031753513030707836, 'happy': 0.8402859792113304, 'sad': 0.11358308838680387, 'surprise': 0.013952216249890625, 'neutral': 98.62743020057678}, 'dominant_emotion': 'neutral', 'region': {'x': 276, 'y': 71, 'w': 312, 'h': 312}, 'face_confidence': 11.482964090013411}]\n",
      "Listening...\n",
      "Speech recognition error: \n",
      "Result: [{'emotion': {'angry': 0.7757399693572503, 'disgust': 6.273062304920605e-09, 'fear': 0.009789414472433297, 'happy': 0.0025541645003520214, 'sad': 0.11773098496234327, 'surprise': 0.0003480708735980195, 'neutral': 99.09383649193266}, 'dominant_emotion': 'neutral', 'region': {'x': 289, 'y': 60, 'w': 321, 'h': 321}, 'face_confidence': 9.792569093580823}]\n",
      "Listening...\n",
      "Speech detected: it was actually a very great day\n",
      "Result: [{'emotion': {'angry': 3.6774884909391403, 'disgust': 7.230341481090363e-06, 'fear': 0.08581565343774855, 'happy': 0.3054742934182286, 'sad': 1.1818066239356995, 'surprise': 0.008290383266285062, 'neutral': 94.74111795425415}, 'dominant_emotion': 'neutral', 'region': {'x': 315, 'y': 95, 'w': 304, 'h': 304}, 'face_confidence': 9.387260125600733}]\n",
      "Listening...\n",
      "Speech detected: also I would like to say that it was such a good day to day I was enjoying I was laughing I was taking rounds of the park it was so fabulous it was so amazing and you know what I was looking just like a Wow\n",
      "Result: [{'emotion': {'angry': 0.20877446513623, 'disgust': 2.5424731120438082e-05, 'fear': 0.9601361118257046, 'happy': 24.01997148990631, 'sad': 0.6941529922187328, 'surprise': 2.7099892497062683, 'neutral': 71.40695452690125}, 'dominant_emotion': 'neutral', 'region': {'x': 306, 'y': 65, 'w': 318, 'h': 318}, 'face_confidence': 6.951715119823348}]\n",
      "Listening...\n",
      "Speech detected: really really cool right this is really very cool\n",
      "Result: [{'emotion': {'angry': 25.01290738582611, 'disgust': 0.0029879845897085033, 'fear': 0.850171223282814, 'happy': 2.415688894689083, 'sad': 6.751573085784912, 'surprise': 0.019676248484756798, 'neutral': 64.94699120521545}, 'dominant_emotion': 'neutral', 'region': {'x': 308, 'y': 118, 'w': 309, 'h': 309}, 'face_confidence': 7.654842067160644}]\n",
      "Listening...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from deepface import DeepFace\n",
    "import speech_recognition as sr\n",
    "from textblob import TextBlob\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize speech recognizer\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Initialize speech timeout counter\n",
    "speech_timeout = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:  \n",
    "        continue  # Skip to the next iteration if the frame is invalid\n",
    "\n",
    "    # Facial expression recognition\n",
    "    try:\n",
    "        result = DeepFace.analyze(frame, actions=['emotion'], enforce_detection=False)\n",
    "        print(\"Result:\", result)  # Print the result to understand its structure\n",
    "        facial_emotion = result[0]['dominant_emotion']\n",
    "    except Exception as e:\n",
    "        print(\"Facial expression recognition error:\", str(e))\n",
    "        facial_emotion = \"Unknown\"\n",
    "\n",
    "    # Speech emotion recognition\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Listening...\")\n",
    "        try:\n",
    "            audio_data = recognizer.listen(source, timeout=5)  # Set timeout for speech recognition\n",
    "            speech_text = recognizer.recognize_google(audio_data)\n",
    "            print(\"Speech detected:\", speech_text)\n",
    "            # Perform speech emotion recognition here\n",
    "            \n",
    "            blob = TextBlob(speech_text)\n",
    "            sentiment_score = blob.sentiment.polarity\n",
    "\n",
    "            # Classify sentiment\n",
    "            if sentiment_score > 0:\n",
    "                 speech_emotion = \"Positive\"\n",
    "            elif sentiment_score < 0:\n",
    "                 speech_emotion = \"Negative\"\n",
    "            else:\n",
    "                 speech_emotion = \"Neutral\"\n",
    "            \n",
    "            speech_timeout = 0  # Reset speech timeout counter\n",
    "        except sr.WaitTimeoutError:\n",
    "            print(\"No speech detected.\")\n",
    "            speech_emotion = \"Unknown\"\n",
    "            speech_timeout += 1\n",
    "            if speech_timeout >= 3:  # If no speech detected for 3 consecutive iterations, break the loop\n",
    "                print(\"Speech timeout reached. Exiting.\")\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(\"Speech recognition error:\", str(e))\n",
    "            speech_emotion = \"Unknown\"\n",
    "\n",
    "    # Combine and display results\n",
    "    combined_emotion = f\"Facial: {facial_emotion} | Speech: {speech_emotion}\"\n",
    "    cv2.putText(frame, combined_emotion, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Multimodal Emotion Detection', frame)\n",
    "\n",
    "    # Break the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190fe859",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
